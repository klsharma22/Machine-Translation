{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9590096b-77e9-4f1e-ba93-874e043953e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc59c072-01c4-4848-823c-4e8fb1b39b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_table('fra.txt', header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6f2ab3-655e-456d-a96e-e1fd3cb05b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns= {0: 'English', 1: 'French', 2: 'Citation'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a157aba8-9988-4afe-bb17-349d365b3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"[!'#$%&()*+,-./:;<=>?@[\\]^`{|}~“”‘’«»‹›„‚–—…·•¡¿’\\\"\\']\"\n",
    "\n",
    "eng_sent, french_sent = [], []\n",
    "\n",
    "for e in range(len(data['English'])):\n",
    "    eng_sent.append(re.sub(pattern, \"\", data['English'][e]))\n",
    "    french_sent.append(re.sub(pattern, \"\", data['French'][e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa56c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229803\n",
      "229803\n"
     ]
    }
   ],
   "source": [
    "print(len(eng_sent))\n",
    "print(len(french_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a724a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_token = [tokenizer.encode(text, add_special_tokens= True) for text in eng_sent]\n",
    "fren_token = [tokenizer.encode(text, add_special_tokens= True) for text in french_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be72bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7daa53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(tokens, max_len):\n",
    "    temp = []\n",
    "    for token in tokens:\n",
    "        if max_len > len(token):\n",
    "            temp.append([token + [tokenizer.pad_token_id \n",
    "                                 for i in range(max_len - len(tokens))]])\n",
    "        else:\n",
    "            temp.append([token[:max_len]])\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ff137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding(batch_tokens, max_len):\n",
    "    batch_padded_tokens = padding(batch_tokens, max_len)\n",
    "    tokens_tensor = torch.tensor(batch_padded_tokens)\n",
    "    with torch.no_grad():\n",
    "        output = model(tokens_tensor)\n",
    "        embeddings = output.last_hidden_state\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "141c9f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average len: 8\n"
     ]
    }
   ],
   "source": [
    "eng_sum = 0\n",
    "for tokens in eng_token:\n",
    "    eng_sum += len(tokens)\n",
    "\n",
    "eng_avg_len = eng_sum // len(eng_token)\n",
    "print(\"Average len: {}\".format(eng_avg_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac102ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average len: 12\n"
     ]
    }
   ],
   "source": [
    "fren_sum = 0\n",
    "for tokens in fren_token:\n",
    "    fren_sum += len(tokens)\n",
    "\n",
    "fren_avg_len = fren_sum // len(fren_token)\n",
    "\n",
    "print(\"Average len: {}\".format(fren_avg_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad72facc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding:   0%|\u001b[32m          \u001b[0m| 0/230 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 1 (got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(eng_token), batch_size), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, colour\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m     batch_token \u001b[38;5;241m=\u001b[39m eng_token[i : i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m----> 6\u001b[0m     eng_embedding\u001b[38;5;241m.\u001b[39mextend(\u001b[43mtext_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meng_avg_len\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mlen\u001b[39m(eng_embedding)\n",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m, in \u001b[0;36mtext_embedding\u001b[0;34m(batch_tokens, max_len)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_embedding\u001b[39m(batch_tokens, max_len):\n\u001b[1;32m      2\u001b[0m     batch_padded_tokens \u001b[38;5;241m=\u001b[39m padding(batch_tokens, max_len)\n\u001b[0;32m----> 3\u001b[0m     tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_padded_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(tokens_tensor)\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 4)"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "eng_embedding = []\n",
    "for i in tqdm(range(0, len(eng_token), batch_size), \"Embedding\", colour= \"green\"):\n",
    "    batch_token = eng_token[i : i+batch_size]\n",
    "    eng_embedding.extend(text_embedding(batch_token, eng_avg_len))\n",
    "\n",
    "len(eng_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdfb5c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding:   0%|\u001b[32m          \u001b[0m| 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 2 (got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(fren_token), batch_size), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, colour\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m     batch_token \u001b[38;5;241m=\u001b[39m fren_token[i : i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m----> 6\u001b[0m     fren_embedding\u001b[38;5;241m.\u001b[39mextend(\u001b[43mtext_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfren_avg_len\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mlen\u001b[39m(fren_embedding)\n",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m, in \u001b[0;36mtext_embedding\u001b[0;34m(batch_tokens, max_len)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_embedding\u001b[39m(batch_tokens, max_len):\n\u001b[1;32m      2\u001b[0m     batch_padded_tokens \u001b[38;5;241m=\u001b[39m padding(batch_tokens, max_len)\n\u001b[0;32m----> 3\u001b[0m     tokens_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_padded_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(tokens_tensor)\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 2 (got 4)"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "\n",
    "fren_embedding = []\n",
    "for i in tqdm(range(0, len(fren_token), batch_size), \"Embedding\", colour= \"green\"):\n",
    "    batch_token = fren_token[i : i+batch_size]\n",
    "    fren_embedding.extend(text_embedding(batch_token, fren_avg_len))\n",
    "\n",
    "len(fren_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee52d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
