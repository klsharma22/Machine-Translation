{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 192,
      "id": "9590096b-77e9-4f1e-ba93-874e043953e6",
      "metadata": {
        "id": "9590096b-77e9-4f1e-ba93-874e043953e6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from transformers import BertTokenizer, BertModel,AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import json\n",
        "import pyarrow\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "ad6f2ab3-655e-456d-a96e-e1fd3cb05b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ad6f2ab3-655e-456d-a96e-e1fd3cb05b54",
        "outputId": "9e1daa5a-df9d-48ed-d15e-d854d2754f62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             English                      French  \\\n",
              "0                Go.                        Va !   \n",
              "1                Go.                     Marche.   \n",
              "2                Go.                  En route !   \n",
              "3                Go.                     Bouge !   \n",
              "4                Hi.                     Salut !   \n",
              "...              ...                         ...   \n",
              "9995  We've made it.          Nous avons réussi.   \n",
              "9996  We've made it.     Nous y sommes parvenus.   \n",
              "9997  We've matured.            Nous avons mûri.   \n",
              "9998  We've no time.  Nous n'avons pas le temps.   \n",
              "9999  We've refused.          Nous avons refusé.   \n",
              "\n",
              "                                               Citation  \n",
              "0     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "1     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "2     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "3     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "4     CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "...                                                 ...  \n",
              "9995  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "9996  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "9997  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
              "9998  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "9999  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d730f9d2-b842-4529-8ce5-813c32c04702\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "      <th>Citation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Marche.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>En route !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Bouge !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>We've made it.</td>\n",
              "      <td>Nous avons réussi.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>We've made it.</td>\n",
              "      <td>Nous y sommes parvenus.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>We've matured.</td>\n",
              "      <td>Nous avons mûri.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>We've no time.</td>\n",
              "      <td>Nous n'avons pas le temps.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>We've refused.</td>\n",
              "      <td>Nous avons refusé.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d730f9d2-b842-4529-8ce5-813c32c04702')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d730f9d2-b842-4529-8ce5-813c32c04702 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d730f9d2-b842-4529-8ce5-813c32c04702');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb96aada-be86-4349-9d0b-63c3389ef6d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb96aada-be86-4349-9d0b-63c3389ef6d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb96aada-be86-4349-9d0b-63c3389ef6d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ad5f6ff9-04df-4114-b091-ace00d9db80b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ad5f6ff9-04df-4114-b091-ace00d9db80b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_table('fra.txt', header= None)\n",
        "data.rename(columns= {0: 'English', 1: 'French', 2: 'Citation'}, inplace= True)\n",
        "data = data[:10000]\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "id": "a157aba8-9988-4afe-bb17-349d365b3286",
      "metadata": {
        "id": "a157aba8-9988-4afe-bb17-349d365b3286"
      },
      "outputs": [],
      "source": [
        "pattern = r\"[!'#$%&()*+,-./:;<=>?@[\\]^`{|}~“”‘’«»‹›„‚–—…·•¡¿’\\\"\\']\"\n",
        "\n",
        "eng_sent, french_sent = [], []\n",
        "\n",
        "for e in range(len(data['English'])):\n",
        "    eng_sent.append(re.sub(pattern, \"\", data['English'][e]))\n",
        "    french_sent.append(re.sub(pattern, \"\", data['French'][e]))\n",
        "#eng_sent[229801]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "id": "fa56c84c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa56c84c",
        "outputId": "dd3ac685-2698-43a4-efc0-0fee037d0bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26262"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ],
      "source": [
        "print(len(eng_sent))\n",
        "print(len(french_sent))\n",
        "def build_vocab(sentence_list):\n",
        "  vocab_list = []\n",
        "  for i in sentence_list:\n",
        "    for j in i.split(' '):\n",
        "      vocab_list.append(j)\n",
        "  return vocab_list\n",
        "eng_vocab = build_vocab(eng_sent)\n",
        "fr_vocab = build_vocab(french_sent)\n",
        "len(eng_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN = ''\n",
        "PADDING_TOKEN = ''\n",
        "END_TOKEN = ''\n",
        "eng_vocab.insert(0,START_TOKEN)\n",
        "eng_vocab.append(PADDING_TOKEN)\n",
        "eng_vocab.append(END_TOKEN)\n",
        "fr_vocab.insert(0,START_TOKEN)\n",
        "fr_vocab.append(PADDING_TOKEN)\n",
        "fr_vocab.append(END_TOKEN)"
      ],
      "metadata": {
        "id": "_n24XkUwNuNk"
      },
      "id": "_n24XkUwNuNk",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_french = {k:v for k,v in enumerate(fr_vocab)}\n",
        "french_to_index = {v:k for k,v in enumerate(fr_vocab)}\n",
        "index_to_english = {k:v for k,v in enumerate(eng_vocab)}\n",
        "english_to_index = {v:k for k,v in enumerate(eng_vocab)}\n",
        "english_to_index['ahead']\n",
        "eng_sent[:4]\n",
        "print(len(english_to_index))\n",
        "print(len(fr_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cfth80qOm0v",
        "outputId": "63874eaa-cd21-44f3-dd52-40241bb4a65a"
      },
      "id": "5Cfth80qOm0v",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2261\n",
            "31938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "french_to_index['Souriez\\u2009']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwcrutz-Evnh",
        "outputId": "22bcf8f7-8ca9-4ec6-f3c9-4329247dd557"
      },
      "id": "Nwcrutz-Evnh",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f4dc7a",
      "metadata": {
        "id": "06f4dc7a"
      },
      "source": [
        "# writing the french embeddings for time saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "74eeea18",
      "metadata": {
        "id": "74eeea18"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_device():\n",
        "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled = scaled.permute(1, 0, 2, 3) + mask\n",
        "        scaled = scaled.permute(1, 0, 2, 3)\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = (torch.arange(self.max_sequence_length)\n",
        "                          .reshape(self.max_sequence_length, 1))\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "        return PE\n",
        "\n",
        "class SentenceEmbedding(nn.Module):\n",
        "    \"For a given sentence, create an embedding\"\n",
        "    def __init__(self, max_sequence_length, d_model, language_to_index, vocab_size, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "        self.language_to_index = language_to_index\n",
        "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.START_TOKEN = START_TOKEN\n",
        "        self.END_TOKEN = END_TOKEN\n",
        "        self.PADDING_TOKEN = PADDING_TOKEN\n",
        "\n",
        "    def batch_tokenize(self, batch, start_token, end_token):\n",
        "\n",
        "        def tokenize(sentence, start_token, end_token):\n",
        "            sentence_word_indicies = [self.language_to_index[token] for token in sentence.split(' ')]\n",
        "            if start_token:\n",
        "                sentence_word_indicies.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "            if end_token:\n",
        "                sentence_word_indicies.append(self.language_to_index[self.END_TOKEN])\n",
        "            for _ in range(len(sentence_word_indicies), self.max_sequence_length):\n",
        "                sentence_word_indicies.append(self.language_to_index[self.PADDING_TOKEN])\n",
        "            return torch.tensor(sentence_word_indicies)\n",
        "\n",
        "        tokenized = []\n",
        "        for sentence_num in range(len(batch)):\n",
        "           tokenized.append( tokenize(batch[sentence_num], start_token, end_token) )\n",
        "        tokenized = torch.stack(tokenized)\n",
        "        return tokenized.to(get_device())\n",
        "\n",
        "    def forward(self, x, start_token, end_token): # sentence\n",
        "        x = self.batch_tokenize(x, start_token, end_token)\n",
        "        print('---------tokenization done --------')\n",
        "        x = self.embedding(x)\n",
        "        print('---------Sentence Embedding done --------')\n",
        "        pos = self.position_encoder().to(get_device())\n",
        "        print('---------Positional Encoding done --------')\n",
        "        x = self.dropout(x + pos)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        batch_size, sequence_length, d_model = x.size()\n",
        "        qkv = self.qkv_layer(x)\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
        "        out = self.linear_layer(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        y = (inputs - mean) / std\n",
        "        out = self.gamma * y + self.beta\n",
        "        return out\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, self_attention_mask):\n",
        "        #print('------------ENCODER ACTIVATED----------')\n",
        "        residual_x = x.clone()\n",
        "        x = self.attention(x, mask=self_attention_mask)\n",
        "        #print('-----------Attention Done---------')\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(x + residual_x)\n",
        "        #print('-----------LayerNorm1 Done---------')\n",
        "        residual_x = x.clone()\n",
        "        x = self.ffn(x)\n",
        "        #print('-----------FFNN Done---------')\n",
        "        x = self.dropout2(x)\n",
        "        x = self.norm2(x + residual_x)\n",
        "        #print('-----------LayerNorm2 Done---------')\n",
        "        return x\n",
        "\n",
        "class SequentialEncoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, self_attention_mask  = inputs\n",
        "        for module in self._modules.values():\n",
        "            x = module(x, self_attention_mask)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 vocab_size,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index,vocab_size, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "                                      for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, self_attention_mask, start_token, end_token):\n",
        "        x = self.sentence_embedding(x, start_token, end_token)\n",
        "        print('DATA PREPROCESSING DONE')\n",
        "        x = self.layers(x, self_attention_mask)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n",
        "        self.q_layer = nn.Linear(d_model , d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, y, mask):\n",
        "        batch_size, sequence_length, d_model = x.size() # in practice, this is the same for both languages...so we can technically combine with normal attention\n",
        "        kv = self.kv_layer(x)\n",
        "        q = self.q_layer(y)\n",
        "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n",
        "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
        "        kv = kv.permute(0, 2, 1, 3)\n",
        "        q = q.permute(0, 2, 1, 3)\n",
        "        k, v = kv.chunk(2, dim=-1)\n",
        "        values, attention = scaled_dot_product(q, k, v, mask) # We don't need the mask for cross attention, removing in outer function!\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n",
        "        out = self.linear_layer(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
        "        _y = y.clone()\n",
        "        y = self.self_attention(y, mask=self_attention_mask)\n",
        "        #print('---------ATTENTION DONE----------')\n",
        "        y = self.dropout1(y)\n",
        "        y = self.layer_norm1(y + _y)\n",
        "       # print('---------layernorm1 DONE----------')\n",
        "        _y = y.clone()\n",
        "        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n",
        "        #print('--------- CROSS ATTENTION DONE----------')\n",
        "        y = self.dropout2(y)\n",
        "        y = self.layer_norm2(y + _y)\n",
        "        #print('---------LayerNorm2 DONE----------')\n",
        "        _y = y.clone()\n",
        "        y = self.ffn(y)\n",
        "        #print('---------FFNN DONE----------')\n",
        "        y = self.dropout3(y)\n",
        "        y = self.layer_norm3(y + _y)\n",
        "       #print('---------LayerNorm3 DONE----------')\n",
        "        return y\n",
        "\n",
        "\n",
        "class SequentialDecoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
        "        for module in self._modules.values():\n",
        "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 vocab_size,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index,vocab_size,START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask, start_token, end_token):\n",
        "        y = self.sentence_embedding(y, start_token, end_token)\n",
        "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                d_model,\n",
        "                ffn_hidden,\n",
        "                num_heads,\n",
        "                drop_prob,\n",
        "                num_layers,\n",
        "                max_sequence_length,\n",
        "                en_vocab_size,\n",
        "                fr_vocab_size,\n",
        "                english_to_index,\n",
        "                french_to_index,\n",
        "                START_TOKEN,\n",
        "                END_TOKEN,\n",
        "                PADDING_TOKEN\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, english_to_index,en_vocab_size, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, french_to_index,fr_vocab_size, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.linear = nn.Linear(d_model, fr_vocab_size)\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    def forward(self,\n",
        "                x,\n",
        "                y,\n",
        "                encoder_self_attention_mask=None,\n",
        "                decoder_self_attention_mask=None,\n",
        "                decoder_cross_attention_mask=None,\n",
        "                enc_start_token=True,\n",
        "                enc_end_token=True,\n",
        "                dec_start_token=True, # We should make this true\n",
        "                dec_end_token=True): # x, y are batch of sentences\n",
        "        x = self.encoder(x, encoder_self_attention_mask, start_token=enc_start_token, end_token=enc_end_token)\n",
        "        print('ENCODER COMPLETED')\n",
        "        print('DECODER ACTIVATED')\n",
        "        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token=dec_start_token, end_token=dec_end_token)\n",
        "        print('DECODER completed')\n",
        "        out = self.linear(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "batch_size = 1\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 5\n",
        "max_sequence_length = 150\n",
        "fr_vocab_size = len(fr_vocab)\n",
        "eng_vocab_size = len(eng_vocab)\n",
        "transformer = Transformer(d_model,\n",
        "                          ffn_hidden,\n",
        "                          num_heads,\n",
        "                          drop_prob,\n",
        "                          num_layers,\n",
        "                          max_sequence_length,\n",
        "                          eng_vocab_size,\n",
        "                          fr_vocab_size,\n",
        "                          english_to_index,\n",
        "                          french_to_index,\n",
        "                          START_TOKEN,\n",
        "                          END_TOKEN,\n",
        "                          PADDING_TOKEN)"
      ],
      "metadata": {
        "id": "DGXD_iE_Psqg"
      },
      "id": "DGXD_iE_Psqg",
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, french_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.french_sentences = french_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.french_sentences[idx]"
      ],
      "metadata": {
        "id": "KZhr6wT0QGsq"
      },
      "id": "KZhr6wT0QGsq",
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(eng_sent[:1000], french_sent[:1000])\n",
        ""
      ],
      "metadata": {
        "id": "NPhU78cqQRuC"
      },
      "id": "NPhU78cqQRuC",
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tidmgKOFQayJ",
        "outputId": "d08efbbc-e18a-4dd6-c15f-8feb466aa8d4"
      },
      "id": "tidmgKOFQayJ",
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ],
      "metadata": {
        "id": "byZtm8oBQfqD"
      },
      "id": "byZtm8oBQfqD",
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "criterian = nn.CrossEntropyLoss(ignore_index=french_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')\n",
        "\n",
        "# When computing the loss, we are ignoring cases when the label is the padding token\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "y8YRbAB3RauY"
      },
      "id": "y8YRbAB3RauY",
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, kn_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, fr_sentence_length = len(eng_batch[idx]), len(fr_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      fr_chars_to_padding_mask = np.arange(fr_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, fr_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, fr_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, fr_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ],
      "metadata": {
        "id": "K98QrSjMR7nn"
      },
      "id": "K98QrSjMR7nn",
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZjTayoEg5mZ",
        "outputId": "36a8d21c-5227-4d4d-9598-5854dd6f561b"
      },
      "id": "OZjTayoEg5mZ",
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Go',), ('Va ',)]\n",
            "[('Go',), ('Marche',)]\n",
            "[('Go',), ('En route ',)]\n",
            "[('Go',), ('Bouge ',)]\n",
            "[('Hi',), ('Salut ',)]\n",
            "[('Hi',), ('Salut',)]\n",
            "[('Run',), ('Cours\\u202f',)]\n",
            "[('Run',), ('Courez\\u202f',)]\n",
            "[('Run',), ('Prenez vos jambes à vos cous ',)]\n",
            "[('Run',), ('File ',)]\n",
            "[('Run',), ('Filez ',)]\n",
            "[('Run',), ('Cours ',)]\n",
            "[('Run',), ('Fuyez ',)]\n",
            "[('Run',), ('Fuyons ',)]\n",
            "[('Run',), ('Cours\\u202f',)]\n",
            "[('Run',), ('Courez\\u202f',)]\n",
            "[('Run',), ('Prenez vos jambes à vos cous ',)]\n",
            "[('Run',), ('File ',)]\n",
            "[('Run',), ('Filez ',)]\n",
            "[('Run',), ('Cours ',)]\n",
            "[('Run',), ('Fuyez ',)]\n",
            "[('Run',), ('Fuyons ',)]\n",
            "[('Who',), ('Qui ',)]\n",
            "[('Wow',), ('Ça alors\\u202f',)]\n",
            "[('Wow',), ('Waouh\\xa0',)]\n",
            "[('Wow',), ('Wah\\xa0',)]\n",
            "[('Duck',), ('À terre\\xa0',)]\n",
            "[('Duck',), ('Baissetoi\\xa0',)]\n",
            "[('Duck',), ('Baissezvous\\xa0',)]\n",
            "[('Fire',), ('Au feu ',)]\n",
            "[('Help',), ('À laide\\u202f',)]\n",
            "[('Hide',), ('Cachetoi',)]\n",
            "[('Hide',), ('Cachezvous',)]\n",
            "[('Jump',), ('Saute',)]\n",
            "[('Jump',), ('Saute',)]\n",
            "[('Stop',), ('Ça suffit\\u202f',)]\n",
            "[('Stop',), ('Stop\\u202f',)]\n",
            "[('Stop',), ('Arrêtetoi ',)]\n",
            "[('Wait',), ('Attends ',)]\n",
            "[('Wait',), ('Attendez ',)]\n",
            "[('Wait',), ('Attendez',)]\n",
            "[('Wait',), ('Attends ',)]\n",
            "[('Wait',), ('Attendez ',)]\n",
            "[('Wait',), ('Attends',)]\n",
            "[('Wait',), ('Attendez',)]\n",
            "[('Begin',), ('Commencez',)]\n",
            "[('Begin',), ('Commence',)]\n",
            "[('Go on',), ('Poursuis',)]\n",
            "[('Go on',), ('Continuez',)]\n",
            "[('Go on',), ('Poursuivez',)]\n",
            "[('Hello',), ('Bonjour ',)]\n",
            "[('Hello',), ('Salut ',)]\n",
            "[('Hello',), ('Bonjour ',)]\n",
            "[('Hello',), ('Salut ',)]\n",
            "[('Hello',), ('Bonjour',)]\n",
            "[('Hello',), ('Salut',)]\n",
            "[('I see',), ('Je comprends',)]\n",
            "[('I see',), ('Aha',)]\n",
            "[('I try',), ('Jessaye',)]\n",
            "[('I won',), ('Jai gagné ',)]\n",
            "[('I won',), ('Je lai emporté ',)]\n",
            "[('I won',), ('Jai gagné',)]\n",
            "[('Oh no',), ('Oh non ',)]\n",
            "[('Relax',), ('Calmetoi',)]\n",
            "[('Relax',), ('Détendstoi\\u202f',)]\n",
            "[('Relax',), ('Détendezvous\\u202f',)]\n",
            "[('Relax',), ('Relaxe Max\\u202f',)]\n",
            "[('Relax',), ('Cool Raoul\\u202f',)]\n",
            "[('Relax',), ('Du calme\\u202f',)]\n",
            "[('Relax',), ('Relaxe ',)]\n",
            "[('Relax',), ('Calmezvous ',)]\n",
            "[('Relax',), ('Détendstoi',)]\n",
            "[('Relax',), ('Détendstoi ',)]\n",
            "[('Relax',), ('Du calme',)]\n",
            "[('Relax',), ('Tranquille',)]\n",
            "[('Smile',), ('Souriez\\u202f',)]\n",
            "[('Smile',), ('Souris pour la caméra',)]\n",
            "[('Smile',), ('Souriez\\u2009',)]\n",
            "[('Sorry',), ('Pardon ',)]\n",
            "[('Attack',), ('Attaque ',)]\n",
            "[('Attack',), ('Attaquez ',)]\n",
            "[('Attack',), ('À lattaque ',)]\n",
            "[('Attack',), ('À lattaque\\xa0',)]\n",
            "[('Buy it',), ('Achetezla ',)]\n",
            "[('Buy it',), ('Achètele ',)]\n",
            "[('Buy it',), ('Achetezle ',)]\n",
            "[('Buy it',), ('Achètela ',)]\n",
            "[('Cheers',), ('Santé ',)]\n",
            "[('Cheers',), ('À votre santé ',)]\n",
            "[('Cheers',), ('Merci ',)]\n",
            "[('Cheers',), ('Tchintchin ',)]\n",
            "[('Eat it',), ('Mangezle',)]\n",
            "[('Eat it',), ('Mangele',)]\n",
            "[('Exhale',), ('Expire',)]\n",
            "[('Get up',), ('Lèvetoi',)]\n",
            "[('Get up',), ('Lèvetoi ',)]\n",
            "[('Get up',), ('Debout',)]\n",
            "[('Go now',), ('Va maintenant',)]\n",
            "[('Go now',), ('Allezy maintenant',)]\n",
            "[('Go now',), ('Vasy maintenant',)]\n",
            "[('Got it',), ('Jai pigé ',)]\n",
            "[('Got it',), ('Compris ',)]\n",
            "[('Got it',), ('Aha ',)]\n",
            "[('Got it',), ('Pigé\\u202f',)]\n",
            "[('Got it',), ('Compris\\u202f',)]\n",
            "[('Got it',), ('Tas capté\\u202f',)]\n",
            "[('Hop in',), ('Monte',)]\n",
            "[('Hop in',), ('Montez',)]\n",
            "[('Hug me',), ('Serremoi dans tes bras ',)]\n",
            "[('Hug me',), ('Serrezmoi dans vos bras ',)]\n",
            "[('I fell',), ('Je suis tombée',)]\n",
            "[('I fell',), ('Je suis tombé',)]\n",
            "[('I fled',), ('Jai fui',)]\n",
            "[('I hunt',), ('Je chasse',)]\n",
            "[('I knit',), ('Je tricote',)]\n",
            "[('I know',), ('Je sais',)]\n",
            "[('I left',), ('Je suis parti',)]\n",
            "[('I left',), ('Je suis partie',)]\n",
            "[('I lied',), ('Jai menti',)]\n",
            "[('I lost',), ('Jai perdu',)]\n",
            "[('I paid',), ('Je payais',)]\n",
            "[('I paid',), ('Je payai',)]\n",
            "[('I paid',), ('Jai payé',)]\n",
            "[('I pass',), ('Je passe',)]\n",
            "[('I quit',), ('Jarrête',)]\n",
            "[('I quit',), ('Jai arrêté',)]\n",
            "[('I swim',), ('Je nage',)]\n",
            "[('Im 19',), ('Jai 19 ans',)]\n",
            "[('Im OK',), ('Je vais bien',)]\n",
            "[('Im OK',), ('Ça va',)]\n",
            "[('Inhale',), ('Inspire',)]\n",
            "[('Listen',), ('Écoutez ',)]\n",
            "[('No way',), ('Cest pas possible\\u202f',)]\n",
            "[('No way',), ('Impossible\\u202f',)]\n",
            "[('No way',), ('Hors de question\\u202f',)]\n",
            "[('No way',), ('En aucun cas',)]\n",
            "[('No way',), ('Sans façons\\u202f',)]\n",
            "[('No way',), ('Mon œil\\u202f',)]\n",
            "[('No way',), ('Cest hors de question ',)]\n",
            "[('No way',), ('Il nen est pas question ',)]\n",
            "[('No way',), ('Cest exclu ',)]\n",
            "[('No way',), ('En aucune manière ',)]\n",
            "[('No way',), ('Hors de question ',)]\n",
            "[('No way',), ('Sans blague ',)]\n",
            "[('Really',), ('Vraiment\\u202f',)]\n",
            "[('Really',), ('Vrai ',)]\n",
            "[('Really',), ('Ah bon ',)]\n",
            "[('Really',), ('Ah vraiment ',)]\n",
            "[('Really',), ('Vraiment ',)]\n",
            "[('Thanks',), ('Merci ',)]\n",
            "[('Thanks',), ('Je te remercie',)]\n",
            "[('Thanks',), ('Merci ',)]\n",
            "[('Thanks',), ('Merci',)]\n",
            "[('Try it',), ('Essaie',)]\n",
            "[('Try it',), ('Essayez',)]\n",
            "[('Try it',), ('Essaye',)]\n",
            "[('We try',), ('On essaye',)]\n",
            "[('We won',), ('Nous avons gagné',)]\n",
            "[('We won',), ('Nous gagnâmes',)]\n",
            "[('We won',), ('Nous lavons emporté',)]\n",
            "[('We won',), ('Nous lemportâmes',)]\n",
            "[('We won',), ('On a gagné',)]\n",
            "[('Ask Tom',), ('Demande à Tom',)]\n",
            "[('Ask him',), ('Demandelui',)]\n",
            "[('Awesome',), ('Fantastique\\u202f',)]\n",
            "[('Awesome',), ('Sensass ',)]\n",
            "[('Awesome',), ('Trop cool ',)]\n",
            "[('Awesome',), ('Génial',)]\n",
            "[('Be calm',), ('Sois calme ',)]\n",
            "[('Be calm',), ('Soyez calme ',)]\n",
            "[('Be calm',), ('Soyez calmes ',)]\n",
            "[('Be cool',), ('Sois détendu ',)]\n",
            "[('Be fair',), ('Sois juste ',)]\n",
            "[('Be fair',), ('Soyez juste ',)]\n",
            "[('Be fair',), ('Soyez justes ',)]\n",
            "[('Be fair',), ('Sois équitable ',)]\n",
            "[('Be fair',), ('Soyez équitable ',)]\n",
            "[('Be fair',), ('Soyez équitables ',)]\n",
            "[('Be fair',), ('Sois honnête',)]\n",
            "[('Be fair',), ('Sois sincère',)]\n",
            "[('Be fair',), ('Soyez honnêtes',)]\n",
            "[('Be kind',), ('Sois gentil',)]\n",
            "[('Be nice',), ('Sois gentil ',)]\n",
            "[('Be nice',), ('Sois gentille ',)]\n",
            "[('Be nice',), ('Soyez gentil ',)]\n",
            "[('Be nice',), ('Soyez gentille ',)]\n",
            "[('Be nice',), ('Soyez gentils ',)]\n",
            "[('Be nice',), ('Soyez gentilles ',)]\n",
            "[('Beat it',), ('Cassezvous\\xa0',)]\n",
            "[('Beat it',), ('Va te faire foutre ',)]\n",
            "[('Beat it',), ('Dégage\\u202f',)]\n",
            "[('Beat it',), ('Cassetoi',)]\n",
            "[('Beat it',), ('Pars ',)]\n",
            "[('Beat it',), ('Foutez le camp ',)]\n",
            "[('Beat it',), ('Fous le camp ',)]\n",
            "[('Beat it',), ('Pars dici',)]\n",
            "[('Beat it',), ('Vaten\\xa0',)]\n",
            "[('Beat it',), ('Disparais ',)]\n",
            "[('Beat it',), ('Fiche le camp',)]\n",
            "[('Beat it',), ('Tiretoi de là',)]\n",
            "[('Beat it',), ('Cassetoi de là',)]\n",
            "[('Beat it',), ('Oust ',)]\n",
            "[('Beat it',), ('Dégage',)]\n",
            "[('Beat it',), ('Fiche le camp dici',)]\n",
            "[('Beat it',), ('Déguerpissez',)]\n",
            "[('Beat it',), ('Bouge ',)]\n",
            "[('Beat it',), ('Décampe ',)]\n",
            "[('Burn it',), ('Brûlezle',)]\n",
            "[('Burn it',), ('Brûlezla',)]\n",
            "[('Burn it',), ('Brûlela',)]\n",
            "[('Burn it',), ('Brûlele',)]\n",
            "[('Bury it',), ('Enterrezle',)]\n",
            "[('Bury it',), ('Enterrele',)]\n",
            "[('Bury it',), ('Enterrezla',)]\n",
            "[('Bury it',), ('Enterrela',)]\n",
            "[('Call me',), ('Appellemoi ',)]\n",
            "[('Call me',), ('Appelezmoi\\xa0',)]\n",
            "[('Call us',), ('Appellenous ',)]\n",
            "[('Call us',), ('Appeleznous ',)]\n",
            "[('Come in',), ('Entrez\\u202f',)]\n",
            "[('Come in',), ('Entre',)]\n",
            "[('Come in',), ('Entre ',)]\n",
            "[('Come in',), ('Entrez ',)]\n",
            "[('Come on',), ('Allez\\u202f',)]\n",
            "[('Come on',), ('En avant\\u202f',)]\n",
            "[('Come on',), ('Allons ',)]\n",
            "[('Come on',), ('Cest pas vrai dis ',)]\n",
            "[('Come on',), ('Viens\\xa0',)]\n",
            "[('Come on',), ('Venez\\u202f',)]\n",
            "[('Come on',), ('Secouezvous ',)]\n",
            "[('Come on',), ('Secouetoi ',)]\n",
            "[('Come on',), ('Allez on y va\\xa0',)]\n",
            "[('Come on',), ('Allez ',)]\n",
            "[('Come on',), ('Viens\\xa0',)]\n",
            "[('Come on',), ('Venez\\u202f',)]\n",
            "[('Drop it',), ('Laisse tomber ',)]\n",
            "[('Drop it',), ('Laissez tomber ',)]\n",
            "[('Drop it',), ('Laissele tomber ',)]\n",
            "[('Drop it',), ('Laissezle tomber ',)]\n",
            "[('Fold it',), ('Pliezle',)]\n",
            "[('Fold it',), ('Pliele',)]\n",
            "[('Fold it',), ('Pliezla',)]\n",
            "[('Fold it',), ('Pliela',)]\n",
            "[('Get Tom',), ('Va chercher Tom',)]\n",
            "[('Get out',), ('Sors',)]\n",
            "[('Get out',), ('Sortez\\u202f',)]\n",
            "[('Get out',), ('Dégage\\u202f',)]\n",
            "[('Get out',), ('Disparais\\u202f',)]\n",
            "[('Get out',), ('Cassetoi',)]\n",
            "[('Get out',), ('Dégagez ',)]\n",
            "[('Get out',), ('Sors ',)]\n",
            "[('Get out',), ('Sortez ',)]\n",
            "[('Get out',), ('Dégage ',)]\n",
            "[('Get out',), ('Disparais ',)]\n",
            "[('Get out',), ('Du balai ',)]\n",
            "[('Get out',), ('Fiche le camp',)]\n",
            "[('Get out',), ('Oust ',)]\n",
            "[('Get out',), ('Vers lextérieur ',)]\n",
            "[('Get out',), ('Fichez le camp ',)]\n",
            "[('Get out',), ('Sortez',)]\n",
            "[('Get out',), ('Décampez ',)]\n",
            "[('Get out',), ('Décampe ',)]\n",
            "[('Get out',), ('Sors',)]\n",
            "[('Get out',), ('Sortez\\u202f',)]\n",
            "[('Get out',), ('Dégage\\u202f',)]\n",
            "[('Get out',), ('Disparais\\u202f',)]\n",
            "[('Get out',), ('Cassetoi',)]\n",
            "[('Get out',), ('Dégagez ',)]\n",
            "[('Get out',), ('Sors ',)]\n",
            "[('Get out',), ('Sortez ',)]\n",
            "[('Get out',), ('Disparais ',)]\n",
            "[('Get out',), ('Fiche le camp',)]\n",
            "[('Get out',), ('Oust ',)]\n",
            "[('Get out',), ('Sortez',)]\n",
            "[('Get out',), ('Bouge ',)]\n",
            "[('Get out',), ('Décampez ',)]\n",
            "[('Get out',), ('Décampe ',)]\n",
            "[('Go away',), ('Dégage\\u202f',)]\n",
            "[('Go away',), ('Pars ',)]\n",
            "[('Go away',), ('Allezvousen\\xa0',)]\n",
            "[('Go away',), ('Déguerpissez',)]\n",
            "[('Go away',), ('Cassezvous',)]\n",
            "[('Go away',), ('Bouge ',)]\n",
            "[('Go away',), ('Décampez ',)]\n",
            "[('Go away',), ('Décampe ',)]\n",
            "[('Go away',), ('Va te faire foutre ',)]\n",
            "[('Go away',), ('Pars ',)]\n",
            "[('Go away',), ('Dégage ',)]\n",
            "[('Go away',), ('Fous le camp ',)]\n",
            "[('Go away',), ('Pars dici',)]\n",
            "[('Go away',), ('Vaten\\xa0',)]\n",
            "[('Go away',), ('Disparais ',)]\n",
            "[('Go away',), ('Déguerpissez',)]\n",
            "[('Go away',), ('Cassezvous',)]\n",
            "[('Go away',), ('Bouge ',)]\n",
            "[('Go away',), ('Décampez ',)]\n",
            "[('Go away',), ('Décampe ',)]\n",
            "[('Go away',), ('Allezvousen',)]\n",
            "[('Go back',), ('Recule',)]\n",
            "[('Go home',), ('Rentrez à la maison',)]\n",
            "[('Go home',), ('Rentre à la maison',)]\n",
            "[('Go home',), ('Rentre chez toi',)]\n",
            "[('Go home',), ('Rentrez chez vous',)]\n",
            "[('Go slow',), ('Va doucement ',)]\n",
            "[('Go slow',), ('Allez doucement ',)]\n",
            "[('Goodbye',), ('Adieu ',)]\n",
            "[('Goodbye',), ('À la revoyure',)]\n",
            "[('Goodbye',), ('Ciao',)]\n",
            "[('Goodbye',), ('Au revoir',)]\n",
            "[('Goodbye',), ('Ciao',)]\n",
            "[('Hang on',), ('Attends un peu ',)]\n",
            "[('Hang on',), ('Attendez un peu ',)]\n",
            "[('Hang on',), ('Attendez',)]\n",
            "[('Hang on',), ('Tiens bon ',)]\n",
            "[('Hang on',), ('Tenez bon ',)]\n",
            "[('Hang on',), ('Attendez',)]\n",
            "[('He left',), ('Il est parti',)]\n",
            "[('He runs',), ('Il court',)]\n",
            "[('Help me',), ('Aidemoi ',)]\n",
            "[('Help me',), ('À laide\\u202f',)]\n",
            "[('Help me',), ('Aidemoi',)]\n",
            "[('Help me',), ('Aidezmoi',)]\n",
            "[('Help me',), ('Aidemoi ',)]\n",
            "[('Help us',), ('Aideznous ',)]\n",
            "[('Help us',), ('Aidenous ',)]\n",
            "[('Hold it',), ('Ne bouge plus ',)]\n",
            "[('Hold it',), ('Ne bougez plus ',)]\n",
            "[('Hold it',), ('Restez où vous êtes ',)]\n",
            "[('Hold it',), ('Attendez',)]\n",
            "[('Hold on',), ('Ne quittez pas',)]\n",
            "[('Hold on',), ('Ne quitte pas ',)]\n",
            "[('Hold up',), ('Tiens bon',)]\n",
            "[('Hold up',), ('Tenez bon',)]\n",
            "[('How sad',), ('Comme cest triste',)]\n",
            "[('Hug Tom',), ('Fais un câlin à Tom',)]\n",
            "[('I agree',), ('Je suis du même avis',)]\n",
            "[('I cried',), ('Jai pleuré',)]\n",
            "[('I dozed',), ('Je me suis assoupi',)]\n",
            "[('I dozed',), ('Je me suis assoupie',)]\n",
            "[('I drive',), ('Je conduis',)]\n",
            "[('I drove',), ('Je conduisis',)]\n",
            "[('I fired',), ('Jai tiré',)]\n",
            "[('I froze',), ('Je me suis figé',)]\n",
            "[('I froze',), ('Je me suis figée',)]\n",
            "[('I smoke',), ('Je fume',)]\n",
            "[('I snore',), ('Je ronfle',)]\n",
            "[('I stink',), ('Je pue',)]\n",
            "[('I stood',), ('Je me suis tenu debout',)]\n",
            "[('I stood',), ('Je me suis tenue debout',)]\n",
            "[('I swore',), ('Jai promis',)]\n",
            "[('I swore',), ('Jai juré',)]\n",
            "[('I tried',), ('Jessayai',)]\n",
            "[('I tried',), ('Jai essayé',)]\n",
            "[('I tried',), ('Jai tenté',)]\n",
            "[('I waved',), ('Jai fait signe',)]\n",
            "[('Ill go',), ('Jirai',)]\n",
            "[('Im Tom',), ('Je suis Tom',)]\n",
            "[('Im fat',), ('Je suis gras',)]\n",
            "[('Im fat',), ('Je suis gros',)]\n",
            "[('Im fit',), ('Je suis en forme',)]\n",
            "[('Im hit',), ('Je suis touché ',)]\n",
            "[('Im hit',), ('Je suis touchée ',)]\n",
            "[('Im ill',), ('Je suis malade',)]\n",
            "[('Im mad',), ('Je suis fou',)]\n",
            "[('Im mad',), ('Je suis folle',)]\n",
            "[('Im mad',), ('Je suis en colère',)]\n",
            "[('Im sad',), ('Je suis triste',)]\n",
            "[('Im sad',), ('Jai un coup de cafard',)]\n",
            "[('Im sad',), ('Je suis malheureux',)]\n",
            "[('Im shy',), ('Je suis timide',)]\n",
            "[('Im wet',), ('Je suis mouillé',)]\n",
            "[('Im wet',), ('Je suis mouillée',)]\n",
            "[('Its me',), ('Cest bibi\\u202f',)]\n",
            "[('Join us',), ('Joignezvous',)]\n",
            "[('Join us',), ('Joignezvous à nous',)]\n",
            "[('Keep it',), ('Gardele ',)]\n",
            "[('Keep it',), ('Gardezle ',)]\n",
            "[('Kick it',), ('Donnelui un coup de pied',)]\n",
            "[('Kick it',), ('Donnezlui un coup de pied',)]\n",
            "[('Kill it',), ('Tuezle',)]\n",
            "[('Kill it',), ('Tuele',)]\n",
            "[('Kill it',), ('Tuela',)]\n",
            "[('Kill it',), ('Tuezla',)]\n",
            "[('Kiss me',), ('Embrassemoi',)]\n",
            "[('Kiss me',), ('Embrassezmoi',)]\n",
            "[('Lie low',), ('À terre ',)]\n",
            "[('Lie low',), ('Au sol ',)]\n",
            "[('Lock it',), ('Verrouillezle',)]\n",
            "[('Lock it',), ('Verrouillele',)]\n",
            "[('Lock it',), ('Verrouillezla',)]\n",
            "[('Lock it',), ('Verrouillela',)]\n",
            "[('Look up',), ('Levez les yeux',)]\n",
            "[('Look up',), ('Lève les yeux',)]\n",
            "[('Me too',), ('Moi aussi',)]\n",
            "[('Me too',), ('À moi aussi',)]\n",
            "[('Move on',), ('Passez à autre chose',)]\n",
            "[('Move on',), ('Passe à autre chose',)]\n",
            "[('Open it',), ('Ouvrezle',)]\n",
            "[('Open it',), ('Ouvrele',)]\n",
            "[('Open it',), ('Ouvrela',)]\n",
            "[('Open it',), ('Ouvrezla',)]\n",
            "[('Open up',), ('Ouvremoi\\u202f',)]\n",
            "[('Open up',), ('Ouvre',)]\n",
            "[('Pair up',), ('Faites équipe',)]\n",
            "[('Perfect',), ('Parfait\\u202f',)]\n",
            "[('Perfect',), ('Nickel\\u202f',)]\n",
            "[('Perfect',), ('Parfait ',)]\n",
            "[('Pull it',), ('Tirez dessus',)]\n",
            "[('Pull it',), ('Tire dessus',)]\n",
            "[('Push it',), ('Appuie dessus',)]\n",
            "[('Push it',), ('Poussezle',)]\n",
            "[('Push it',), ('Poussele',)]\n",
            "[('Push it',), ('Poussezla',)]\n",
            "[('Push it',), ('Poussela',)]\n",
            "[('See you',), ('À plus tard\\xa0',)]\n",
            "[('See you',), ('À bientôt ',)]\n",
            "[('See you',), ('À la prochaine ',)]\n",
            "[('See you',), ('Ciao',)]\n",
            "[('See you',), ('À plus',)]\n",
            "[('See you',), ('Ciao',)]\n",
            "[('Show me',), ('Montremoi ',)]\n",
            "[('Show me',), ('Montrezmoi ',)]\n",
            "[('Shut up',), ('Taisezvous\\u202f',)]\n",
            "[('Shut up',), ('Fermela\\u202f',)]\n",
            "[('Shut up',), ('Taistoi ',)]\n",
            "[('Shut up',), ('Fermela ',)]\n",
            "[('Shut up',), ('La ferme ',)]\n",
            "[('Shut up',), ('Bouclezla ',)]\n",
            "[('Shut up',), ('Fermezla\\xa0',)]\n",
            "[('Shut up',), ('Fermela\\xa0',)]\n",
            "[('Sign up',), ('Inscrivezvous',)]\n",
            "[('Sign up',), ('Inscristoi',)]\n",
            "[('Skip it',), ('Laisse tomber',)]\n",
            "[('Skip it',), ('Pas grave',)]\n",
            "[('So long',), ('À plus tard\\xa0',)]\n",
            "[('Take it',), ('Prendsle\\u202f',)]\n",
            "[('Take it',), ('Prenezle\\u202f',)]\n",
            "[('Take it',), ('Prendsle ',)]\n",
            "[('Take it',), ('Prenezle ',)]\n",
            "[('Take it',), ('Prenezle',)]\n",
            "[('Take it',), ('Prendsle',)]\n",
            "[('Tell me',), ('Dismoi ',)]\n",
            "[('Tell me',), ('Ditesmoi ',)]\n",
            "[('Tom won',), ('Tom a gagné',)]\n",
            "[('Wake up',), ('Réveilletoi\\u202f',)]\n",
            "[('Wake up',), ('Réveilletoi ',)]\n",
            "[('Wake up',), ('Réveillezvous ',)]\n",
            "[('Wake up',), ('Réveilletoi ',)]\n",
            "[('Wake up',), ('Réveillezvous ',)]\n",
            "[('Wash up',), ('Lavetoi ',)]\n",
            "[('Wash up',), ('Lavezvous ',)]\n",
            "[('We care',), ('Nous nous en soucions',)]\n",
            "[('We know',), ('Nous savons',)]\n",
            "[('We know',), ('On sait',)]\n",
            "[('We lost',), ('Nous perdîmes',)]\n",
            "[('We lost',), ('Nous avons perdu',)]\n",
            "[('We lost',), ('Nous fûmes battus',)]\n",
            "[('We lost',), ('Nous fûmes battues',)]\n",
            "[('We lost',), ('Nous fûmes défaits',)]\n",
            "[('We lost',), ('Nous fûmes défaites',)]\n",
            "[('We lost',), ('Nous avons été défaits',)]\n",
            "[('We lost',), ('Nous avons été défaites',)]\n",
            "[('We lost',), ('Nous avons été battus',)]\n",
            "[('We lost',), ('Nous avons été battues',)]\n",
            "[('Welcome',), ('Bienvenue\\u202f',)]\n",
            "[('Welcome',), ('Soyez le bienvenu ',)]\n",
            "[('Who ran',), ('Qui courait\\xa0',)]\n",
            "[('Who won',), ('Qui a gagné ',)]\n",
            "[('Who won',), ('Qui la emporté ',)]\n",
            "[('You run',), ('Tu cours',)]\n",
            "[('You win',), ('Vous avez gagné',)]\n",
            "[('Aim high',), ('Visez haut',)]\n",
            "[('Aim high',), ('Vise haut',)]\n",
            "[('Am I fat',), ('Suisje gros ',)]\n",
            "[('Am I fat',), ('Suisje grosse ',)]\n",
            "[('Ask them',), ('Demandeleur',)]\n",
            "[('Ask them',), ('Demandezleur',)]\n",
            "[('Back off',), ('Recule\\u2009',)]\n",
            "[('Back off',), ('Reculez',)]\n",
            "[('Back off',), ('Cassezvous',)]\n",
            "[('Back off',), ('Recule\\u2009',)]\n",
            "[('Back off',), ('Reculez',)]\n",
            "[('Back off',), ('Retiretoi\\u2009',)]\n",
            "[('Back off',), ('Retirezvous',)]\n",
            "[('Back off',), ('Cassezvous',)]\n",
            "[('Be a man',), ('Sois un homme ',)]\n",
            "[('Be a man',), ('Soyez un homme ',)]\n",
            "[('Be brave',), ('Soyez courageux ',)]\n",
            "[('Be brief',), ('Soyez bref',)]\n",
            "[('Be brief',), ('Sois bref',)]\n",
            "[('Be brief',), ('Sois brève',)]\n",
            "[('Be brief',), ('Soyez brève',)]\n",
            "[('Be brief',), ('Soyez brefs',)]\n",
            "[('Be brief',), ('Soyez brèves',)]\n",
            "[('Be still',), ('Sois calme ',)]\n",
            "[('Be still',), ('Soyez calme ',)]\n",
            "[('Be still',), ('Soyez calmes ',)]\n",
            "[('Buzz off',), ('Cassetoi',)]\n",
            "[('Call Tom',), ('Appelle Tom',)]\n",
            "[('Call Tom',), ('Appelez Tom',)]\n",
            "[('Can I go',), ('Je peux y aller\\xa0',)]\n",
            "[('Cheer up',), ('Courage\\u202f',)]\n",
            "[('Cheer up',), ('Courage\\u202f',)]\n",
            "[('Cool off',), ('Détendstoi\\u202f',)]\n",
            "[('Cover me',), ('Couvremoi',)]\n",
            "[('Cuff him',), ('Menottezle',)]\n",
            "[('Drive on',), ('Avance ',)]\n",
            "[('Drive on',), ('Avancez ',)]\n",
            "[('Drive on',), ('Continue à rouler ',)]\n",
            "[('Drive on',), ('Continuez à rouler ',)]\n",
            "[('Find Tom',), ('Trouve Tom',)]\n",
            "[('Find Tom',), ('Trouvez Tom',)]\n",
            "[('Fix this',), ('Réparez ceci',)]\n",
            "[('Fix this',), ('Répare ça',)]\n",
            "[('Get away',), ('Dégage\\u202f',)]\n",
            "[('Get away',), ('Cassetoi',)]\n",
            "[('Get away',), ('Pars ',)]\n",
            "[('Get away',), ('Dégage ',)]\n",
            "[('Get away',), ('Fous le camp ',)]\n",
            "[('Get away',), ('Pars dici',)]\n",
            "[('Get away',), ('Vaten\\xa0',)]\n",
            "[('Get away',), ('Écartetoi ',)]\n",
            "[('Get away',), ('Disparais ',)]\n",
            "[('Get away',), ('Allezvousen\\xa0',)]\n",
            "[('Get away',), ('Fiche le camp',)]\n",
            "[('Get away',), ('Tiretoi de là',)]\n",
            "[('Get away',), ('Dégage',)]\n",
            "[('Get away',), ('Vaten ',)]\n",
            "[('Get away',), ('Criss ton camp dicit ',)]\n",
            "[('Get away',), ('Fichez le camp',)]\n",
            "[('Get away',), ('Déguerpissez',)]\n",
            "[('Get away',), ('Cassezvous',)]\n",
            "[('Get away',), ('Barrezvous',)]\n",
            "[('Get away',), ('Barretoi',)]\n",
            "[('Get away',), ('Vaten ',)]\n",
            "[('Get away',), ('Bouge ',)]\n",
            "[('Get away',), ('Décampez ',)]\n",
            "[('Get away',), ('Décampe ',)]\n",
            "[('Get away',), ('Tu dis nimporte quoi\\xa0',)]\n",
            "[('Get away',), ('Pars',)]\n",
            "[('Get away',), ('Partez',)]\n",
            "[('Get down',), ('Lâchetoi ',)]\n",
            "[('Get down',), ('À terre ',)]\n",
            "[('Get down',), ('Au sol ',)]\n",
            "[('Get down',), ('Descends',)]\n",
            "[('Get down',), ('Descends ',)]\n",
            "[('Get down',), ('Descendez ',)]\n",
            "[('Get down',), ('Lâchetoi ',)]\n",
            "[('Get down',), ('Lâchezvous ',)]\n",
            "[('Get down',), ('À terre ',)]\n",
            "[('Get down',), ('Au sol ',)]\n",
            "[('Get down',), ('Descends',)]\n",
            "[('Get lost',), ('Va voir ailleurs si jy suis\\u202f',)]\n",
            "[('Get lost',), ('Dégage\\u202f',)]\n",
            "[('Get lost',), ('Va au diable ',)]\n",
            "[('Get lost',), ('Déguerpissez',)]\n",
            "[('Get lost',), ('Cassezvous',)]\n",
            "[('Get lost',), ('Bouge ',)]\n",
            "[('Get lost',), ('Décampez ',)]\n",
            "[('Get lost',), ('Décampe ',)]\n",
            "[('Get lost',), ('Va te faire foutre\\xa0',)]\n",
            "[('Get lost',), ('Va te faire voir\\xa0',)]\n",
            "[('Get lost',), ('Fiche le camp',)]\n",
            "[('Get lost',), ('Fichez le camp',)]\n",
            "[('Get lost',), ('Déguerpissez',)]\n",
            "[('Get lost',), ('Cassezvous',)]\n",
            "[('Get lost',), ('Bouge ',)]\n",
            "[('Get lost',), ('Décampez ',)]\n",
            "[('Get lost',), ('Décampe ',)]\n",
            "[('Get real',), ('Sois réaliste ',)]\n",
            "[('Get real',), ('Tu délires\\xa0',)]\n",
            "[('Go ahead',), ('Allez\\u202f',)]\n",
            "[('Go ahead',), ('Vasy',)]\n",
            "[('Go ahead',), ('En avant\\u202f',)]\n",
            "[('Go ahead',), ('Va ',)]\n",
            "[('Go ahead',), ('Poursuis ',)]\n",
            "[('Go ahead',), ('Poursuivez ',)]\n",
            "[('Go ahead',), ('Passe devant ',)]\n",
            "[('Go ahead',), ('Vasy ',)]\n",
            "[('Go ahead',), ('Allezy ',)]\n",
            "[('Go ahead',), ('Continuez ',)]\n",
            "[('Go ahead',), ('Continue ',)]\n",
            "[('Go ahead',), ('Allez ',)]\n",
            "[('Go ahead',), ('Avance ',)]\n",
            "[('Go ahead',), ('En avant\\xa0',)]\n",
            "[('Go ahead',), ('Allez\\u202f',)]\n",
            "[('Go ahead',), ('Vasy',)]\n",
            "[('Go ahead',), ('Va ',)]\n",
            "[('Go ahead',), ('Poursuis ',)]\n",
            "[('Go ahead',), ('Poursuivez ',)]\n",
            "[('Go ahead',), ('Passe devant ',)]\n",
            "[('Go ahead',), ('Vasy ',)]\n",
            "[('Go ahead',), ('Allezy ',)]\n",
            "[('Go ahead',), ('Continuez ',)]\n",
            "[('Go ahead',), ('Continue ',)]\n",
            "[('Go ahead',), ('Allez ',)]\n",
            "[('Go ahead',), ('Avance ',)]\n",
            "[('Go ahead',), ('En route ',)]\n",
            "[('Good job',), ('Bien joué\\u202f',)]\n",
            "[('Good job',), ('Bon boulot\\u202f',)]\n",
            "[('Good job',), ('Beau travail\\u202f',)]\n",
            "[('Good job',), ('Bravo ',)]\n",
            "[('Grab Tom',), ('Attrape Tom',)]\n",
            "[('Grab Tom',), ('Attrapez Tom',)]\n",
            "[('Grab him',), ('Attrapele',)]\n",
            "[('Grab him',), ('Attrapezle',)]\n",
            "[('Grab him',), ('Mettezlui la main dessus ',)]\n",
            "[('Have fun',), ('Amusetoi bien ',)]\n",
            "[('Have fun',), ('Amusezvous bien ',)]\n",
            "[('Have fun',), ('Amusetoi bien',)]\n",
            "[('Have fun',), ('Amusezvous bien',)]\n",
            "[('He spoke',), ('Il a parlé',)]\n",
            "[('He spoke',), ('Il a pris la parole',)]\n",
            "[('He spoke',), ('Il sest exprimé',)]\n",
            "[('He tries',), ('Il essaye',)]\n",
            "[('Hes wet',), ('Il est mouillé',)]\n",
            "[('Help Tom',), ('Aide Tom',)]\n",
            "[('Help Tom',), ('Aidez Tom',)]\n",
            "[('Help Tom',), ('Aidez Tom ',)]\n",
            "[('Hi guys',), ('Salut les mecs ',)]\n",
            "[('How cute',), ('Comme cest mignon\\u202f',)]\n",
            "[('How cute',), ('Trop mignon ',)]\n",
            "[('How cute',), ('Trop mignonne ',)]\n",
            "[('How deep',), ('Quelle profondeur\\u202f',)]\n",
            "[('How nice',), ('Comme elle est belle\\u202f',)]\n",
            "[('How nice',), ('Comme cest chouette ',)]\n",
            "[('How nice',), ('Comme cest gentil ',)]\n",
            "[('How nice',), ('Cest du joli ',)]\n",
            "[('How nice',), ('Comme cest agréable ',)]\n",
            "[('How rude',), ('Quelle grossièreté ',)]\n",
            "[('How wise',), ('Quelle sagesse ',)]\n",
            "[('Hurry up',), ('Dépêchetoi',)]\n",
            "[('Hurry up',), ('Grouille\\u202f',)]\n",
            "[('Hurry up',), ('Pressezvous ',)]\n",
            "[('Hurry up',), ('Fiça ',)]\n",
            "[('Hurry up',), ('Magnetoi ',)]\n",
            "[('Hurry up',), ('Magnezvous ',)]\n",
            "[('I am Tom',), ('Je suis Tom',)]\n",
            "[('I cursed',), ('Jai juré',)]\n",
            "[('I did OK',), ('Je men suis bien sorti',)]\n",
            "[('I did OK',), ('Je men suis bien sortie',)]\n",
            "[('I did it',), ('Je lai fait',)]\n",
            "[('I did it',), ('Cest moi qui lai fait',)]\n",
            "[('I failed',), ('Jai échoué',)]\n",
            "[('I forgot',), ('Jai oublié',)]\n",
            "[('I get it',), ('Jai compris',)]\n",
            "[('I goofed',), ('Jai fait une gaffe',)]\n",
            "[('I got it',), ('Jai compris',)]\n",
            "[('I got it',), ('Jai capté',)]\n",
            "[('I helped',), ('Jai aidé',)]\n",
            "[('I jumped',), ('Jai sauté',)]\n",
            "[('I looked',), ('Jai regardé',)]\n",
            "[('I moaned',), ('Jai râlé',)]\n",
            "[('I nodded',), ('Jai fait signe de la tête',)]\n",
            "[('I obeyed',), ('Jai obéi',)]\n",
            "[('I phoned',), ('Je téléphonai',)]\n",
            "[('I phoned',), ('Jai téléphoné',)]\n",
            "[('I refuse',), ('Je refuse',)]\n",
            "[('I refuse',), ('Je le refuse',)]\n",
            "[('I rested',), ('Je me suis reposé',)]\n",
            "[('I rested',), ('Je me suis reposée',)]\n",
            "[('I saw it',), ('Je lai vu',)]\n",
            "[('I saw it',), ('Je lai vu',)]\n",
            "[('I sighed',), ('Jai soupiré',)]\n",
            "[('I smiled',), ('Jai souri',)]\n",
            "[('I stayed',), ('Je suis resté',)]\n",
            "[('I stayed',), ('Je suis restée',)]\n",
            "[('I talked',), ('Jai parlé',)]\n",
            "[('I use it',), ('Je lutilise',)]\n",
            "[('I use it',), ('Jen fais usage',)]\n",
            "[('I use it',), ('Je men sers',)]\n",
            "[('Ill pay',), ('Je paierai',)]\n",
            "[('Ill pay',), ('Je paie',)]\n",
            "[('Ill try',), ('Je vais essayer',)]\n",
            "[('Ill try',), ('Jessaierai',)]\n",
            "[('Im back',), ('Je suis revenu',)]\n",
            "[('Im back',), ('Me revoilà',)]\n",
            "[('Im bald',), ('Je suis chauve',)]\n",
            "[('Im busy',), ('Je suis occupé',)]\n",
            "[('Im busy',), ('Je suis occupée',)]\n",
            "[('Im calm',), ('Je suis calme',)]\n",
            "[('Im cold',), ('Jai froid',)]\n",
            "[('Im cool',), ('Je suis détendu',)]\n",
            "[('Im cool',), ('Je suis détendue',)]\n",
            "[('Im deaf',), ('Je suis sourd',)]\n",
            "[('Im deaf',), ('Je suis sourde',)]\n",
            "[('Im done',), ('Jen ai fini',)]\n",
            "[('Im fair',), ('Je suis juste',)]\n",
            "[('Im fair',), ('Jai la peau claire',)]\n",
            "[('Im fair',), ('Jai le teint clair',)]\n",
            "[('Im fast',), ('Je suis rapide',)]\n",
            "[('Im fine',), ('Tout va bien',)]\n",
            "[('Im fine',), ('Je vais bien',)]\n",
            "[('Im fine',), ('Ça va',)]\n",
            "[('Im free',), ('Je suis libre ',)]\n",
            "[('Im free',), ('Je suis libre',)]\n",
            "[('Im free',), ('Je suis disponible',)]\n",
            "[('Im full',), ('Je suis repu\\u202f',)]\n",
            "[('Im full',), ('Je suis rassasié\\u202f',)]\n",
            "[('Im game',), ('Jen suis',)]\n",
            "[('Im game',), ('Je suis de la partie',)]\n",
            "[('Im glad',), ('Je suis content',)]\n",
            "[('Im good',), ('Je vais bien',)]\n",
            "[('Im good',), ('Je suis bon',)]\n",
            "[('Im home',), ('Je suis chez moi',)]\n",
            "[('Im late',), ('Je suis en retard',)]\n",
            "[('Im lazy',), ('Je suis paresseux',)]\n",
            "[('Im lazy',), ('Je suis fainéant',)]\n",
            "[('Im lazy',), ('Je suis paresseuse',)]\n",
            "[('Im lazy',), ('Je suis fainéante',)]\n",
            "[('Im lost',), ('Je suis paumé',)]\n",
            "[('Im lost',), ('Je suis perdue',)]\n",
            "[('Im okay',), ('Je vais bien',)]\n",
            "[('Im okay',), ('Je me porte bien',)]\n",
            "[('Im rich',), ('Je suis riche',)]\n",
            "[('Im safe',), ('Je suis en sécurité',)]\n",
            "[('Im sick',), ('Je suis malade',)]\n",
            "[('Im sure',), ('Jen suis certain',)]\n",
            "[('Im sure',), ('Je suis certain',)]\n",
            "[('Im sure',), ('Jen suis sûr',)]\n",
            "[('Im sure',), ('Jen suis sûre',)]\n",
            "[('Im tall',), ('Je suis grande',)]\n",
            "[('Im thin',), ('Je suis mince',)]\n",
            "[('Im tidy',), ('Je suis ordonné',)]\n",
            "[('Im tidy',), ('Je suis ordonnée',)]\n",
            "[('Im ugly',), ('Je suis laid',)]\n",
            "[('Im ugly',), ('Je suis laide',)]\n",
            "[('Im ugly',), ('Je suis moche',)]\n",
            "[('Im weak',), ('Je suis faible',)]\n",
            "[('Im well',), ('Je vais bien',)]\n",
            "[('Im well',), ('Je me porte bien',)]\n",
            "[('Ive won',), ('Jai gagné',)]\n",
            "[('Ive won',), ('Je lai emporté',)]\n",
            "[('It helps',), ('Ça aide',)]\n",
            "[('It hurts',), ('Ça fait mal',)]\n",
            "[('It works',), ('Elle marche',)]\n",
            "[('It works',), ('Ça fonctionne',)]\n",
            "[('Its Tom',), ('Cest Tom',)]\n",
            "[('Its fun',), ('Cest marrant',)]\n",
            "[('Its fun',), ('Cest rigolo',)]\n",
            "[('Its his',), ('Cest le sien',)]\n",
            "[('Its his',), ('Cest la sienne',)]\n",
            "[('Its hot',), ('Cest chaud',)]\n",
            "[('Its new',), ('Cest nouveau',)]\n",
            "[('Its new',), ('Cest neuf',)]\n",
            "[('Its odd',), ('Cest bizarre',)]\n",
            "[('Its red',), ('Il est rouge',)]\n",
            "[('Its sad',), ('Cest triste',)]\n",
            "[('Keep out',), ('Défense dentrer',)]\n",
            "[('Keep out',), ('Nentrez pas',)]\n",
            "[('Kill Tom',), ('Tuez Tom',)]\n",
            "[('Kill Tom',), ('Tue Tom',)]\n",
            "[('Kiss Tom',), ('Embrasse Tom',)]\n",
            "[('Leave it',), ('Laisse tomber ',)]\n",
            "[('Leave it',), ('Laissez tomber ',)]\n",
            "[('Leave it',), ('Laisse ',)]\n",
            "[('Leave it',), ('Laissez ça',)]\n",
            "[('Leave it',), ('Laisse ça',)]\n",
            "[('Leave me',), ('Laissezmoi ',)]\n",
            "[('Leave us',), ('Laissenous ',)]\n",
            "[('Leave us',), ('Laisseznous ',)]\n",
            "[('Lets go',), ('Allonsy ',)]\n",
            "[('Lets go',), ('Allons ',)]\n",
            "[('Lets go',), ('En route ',)]\n",
            "[('Lets go',), ('Allonsy ',)]\n",
            "[('Lets go',), ('En route ',)]\n",
            "[('Look out',), ('Attention ',)]\n",
            "[('Look out',), ('Faites attention\\u202f',)]\n",
            "[('Look out',), ('Fais attention\\u202f',)]\n",
            "[('Look out',), ('Soyez prudente ',)]\n",
            "[('Look out',), ('Fais gaffe ',)]\n",
            "[('Look out',), ('Faites gaffe ',)]\n",
            "[('Look out',), ('Fais attention ',)]\n",
            "[('Look out',), ('Regarde donc ',)]\n",
            "[('Look out',), ('Faites attention',)]\n",
            "[('Look out',), ('Fais attention',)]\n",
            "[('Marry me',), ('Épousemoi ',)]\n",
            "[('Marry me',), ('Épousezmoi ',)]\n",
            "[('May I go',), ('Puisje partir ',)]\n",
            "[('May I go',), ('Puisje y aller ',)]\n",
            "[('May I go',), ('Puisje my rendre ',)]\n",
            "[('Nice try',), ('Belle tentative',)]\n",
            "[('Now stop',), ('Arrêtezvous maintenant\\xa0',)]\n",
            "[('Now stop',), ('Arrêtetoi maintenant\\xa0',)]\n",
            "[('Prove it',), ('Prouvezle',)]\n",
            "[('Prove it',), ('Prouvele',)]\n",
            "[('Run away',), ('Fuyez',)]\n",
            "[('Run away',), ('Fuis',)]\n",
            "[('Run away',), ('Enfuyezvous',)]\n",
            "[('Run away',), ('Enfuistoi',)]\n",
            "[('Save Tom',), ('Sauve Tom',)]\n",
            "[('Save Tom',), ('Sauvez Tom',)]\n",
            "[('Say what',), ('De quoi\\u202f',)]\n",
            "[('She came',), ('Elle est venue',)]\n",
            "[('She died',), ('Elle est morte',)]\n",
            "[('She left',), ('Elle est partie',)]\n",
            "[('She runs',), ('Elle court',)]\n",
            "[('Sit down',), ('Assiedstoi ',)]\n",
            "[('Sit down',), ('Asseyezvous ',)]\n",
            "[('Sit down',), ('Asseyezvous',)]\n",
            "[('Sit down',), ('Assiedstoi',)]\n",
            "[('Sit down',), ('Asseyezvous',)]\n",
            "[('Sit here',), ('Assiedstoi ici',)]\n",
            "[('Sit here',), ('Asseyezvous ici',)]\n",
            "[('Speak up',), ('Parle plus fort\\u202f',)]\n",
            "[('Speak up',), ('Parlez plus fort\\u202f',)]\n",
            "[('Speak up',), ('Parle plus fort ',)]\n",
            "[('Speed up',), ('Accélère',)]\n",
            "[('Speed up',), ('Accélérez',)]\n",
            "[('Stand up',), ('Lèvetoi',)]\n",
            "[('Stop Tom',), ('Arrête Tom',)]\n",
            "[('Stop Tom',), ('Stoppez Tom',)]\n",
            "[('Take Tom',), ('Prends Tom',)]\n",
            "[('Taste it',), ('Goûtele',)]\n",
            "[('Taste it',), ('Goûtela',)]\n",
            "[('Taste it',), ('Goûtezle',)]\n",
            "[('Taste it',), ('Goûtezla',)]\n",
            "[('Tell Tom',), ('Disle à Tom',)]\n",
            "[('Tell Tom',), ('Informezen Tom',)]\n",
            "[('Terrific',), ('Fantastique\\u202f',)]\n",
            "[('Terrific',), ('Génial\\u202f',)]\n",
            "[('Terrific',), ('Super\\u202f',)]\n",
            "[('Terrific',), ('Au poil\\u202f',)]\n",
            "[('Terrific',), ('Impeccable\\u202f',)]\n",
            "[('Terrific',), ('Nickel\\u202f',)]\n",
            "[('Terrific',), ('Excellent\\u202f',)]\n",
            "[('Terrific',), ('Magnifique\\u202f',)]\n",
            "[('Terrific',), ('Nickel chrome\\u202f',)]\n",
            "[('Terrific',), ('Bien',)]\n",
            "[('Terrific',), ('Formidable ',)]\n",
            "[('Terrific',), ('Cest génial ',)]\n",
            "[('Terrific',), ('À la bonne heure ',)]\n",
            "[('Terrific',), ('Cest super',)]\n",
            "[('Terrific',), ('Super ',)]\n",
            "[('Terrific',), ('Génial ',)]\n",
            "[('Terrific',), ('Sensass ',)]\n",
            "[('They won',), ('Ils gagnèrent',)]\n",
            "[('They won',), ('Elles gagnèrent',)]\n",
            "[('They won',), ('Ils ont gagné',)]\n",
            "[('They won',), ('Elles ont gagné',)]\n",
            "[('Tom came',), ('Tom est venu',)]\n",
            "[('Tom died',), ('Tom est mort',)]\n",
            "[('Tom knew',), ('Tom savait',)]\n",
            "[('Tom left',), ('Tom est parti',)]\n",
            "[('Tom left',), ('Tom partit',)]\n",
            "[('Tom lied',), ('Tom a menti',)]\n",
            "[('Tom lies',), ('Tom ment',)]\n",
            "[('Tom lost',), ('Tom a perdu',)]\n",
            "[('Tom paid',), ('Tom a payé',)]\n",
            "[('Tom paid',), ('Tom payait',)]\n",
            "[('Tom went',), ('Tom est parti',)]\n",
            "[('Toms up',), ('Tom est debout',)]\n",
            "[('Too late',), ('Trop tard',)]\n",
            "[('Touch it',), ('Touchezle',)]\n",
            "[('Touch it',), ('Touchezla',)]\n",
            "[('Touch it',), ('Touchele',)]\n",
            "[('Touch it',), ('Touchela',)]\n",
            "[('Trust me',), ('Faismoi confiance\\u202f',)]\n",
            "[('Trust me',), ('Faitesmoi confiance',)]\n",
            "[('Trust me',), ('Faismoi confiance',)]\n",
            "[('Trust me',), ('Ayez confiance en moi',)]\n",
            "[('Trust me',), ('Aie confiance en moi',)]\n",
            "[('Try some',), ('Essaiesen ',)]\n",
            "[('Try some',), ('Essayezen ',)]\n",
            "[('Try some',), ('Essaie',)]\n",
            "[('Try this',), ('Essaie ceci ',)]\n",
            "[('Try this',), ('Essayez ceci ',)]\n",
            "[('Try this',), ('Essaye ceci',)]\n",
            "[('Use this',), ('Utilise ceci',)]\n",
            "[('Use this',), ('Utilisez ceci',)]\n",
            "[('Use this',), ('Emploie ceci ',)]\n",
            "[('Use this',), ('Employez ceci ',)]\n",
            "[('Warn Tom',), ('Avertis Tom',)]\n",
            "[('Warn Tom',), ('Préviens Tom',)]\n",
            "[('Watch me',), ('Regardemoi ',)]\n",
            "[('Watch me',), ('Regardezmoi ',)]\n",
            "[('Watch us',), ('Regardeznous ',)]\n",
            "[('Watch us',), ('Regardenous ',)]\n",
            "[('We agree',), ('Nous sommes daccord',)]\n",
            "[('Well go',), ('Nous irons',)]\n",
            "[('Were OK',), ('Nous allons bien',)]\n",
            "[('What for',), ('Pour quoi faire\\u202f',)]\n",
            "[('What for',), ('À quoi bon ',)]\n",
            "[('What fun',), ('Questce quon sest marrés ',)]\n",
            "[('What fun',), ('Questce quon sest marrées ',)]\n",
            "[('Who am I',), ('Qui suisje ',)]\n",
            "[('Who came',), ('Qui est venu ',)]\n",
            "[('Who died',), ('Qui est mort ',)]\n",
            "[('Who fell',), ('Qui est tombé\\xa0',)]\n",
            "[('Who lost',), ('Qui a perdu ',)]\n",
            "[('Who paid',), ('Qui a payé\\xa0',)]\n",
            "[('Who quit',), ('Qui démissionne\\xa0',)]\n",
            "[('Whos he',), ('Qui estil\\u202f',)]\n",
            "[('Write me',), ('Écrismoi ',)]\n",
            "[('Write me',), ('Écrivezmoi ',)]\n",
            "[('You lost',), ('Tu as perdu',)]\n",
            "[('You lost',), ('Vous avez perdu',)]\n",
            "[('You lost',), ('Tas perdu',)]\n",
            "[('After you',), ('Je vous en prie',)]\n",
            "[('After you',), ('Après vous',)]\n",
            "[('After you',), ('À vous lhonneur',)]\n",
            "[('After you',), ('À toi lhonneur',)]\n",
            "[('Aim Fire',), ('En joue  Feu ',)]\n",
            "[('Am I cute',), ('Suisje mignon ',)]\n",
            "[('Am I late',), ('Suisje en retard ',)]\n",
            "[('Answer me',), ('Répondezmoi',)]\n",
            "[('Be honest',), ('Sois honnête',)]\n",
            "[('Be honest',), ('Soyez honnêtes',)]\n",
            "[('Be honest',), ('Soyez honnête',)]\n",
            "[('Be seated',), ('Assiedstoi ',)]\n",
            "[('Be seated',), ('Asseyezvous ',)]\n",
            "[('Be seated',), ('Asseyezvous',)]\n",
            "[('Be strong',), ('Sois puissante\\xa0',)]\n",
            "[('Birds fly',), ('Les oiseaux volent',)]\n",
            "[('Bless you',), ('À tes souhaits\\u202f',)]\n",
            "[('Call home',), ('Appelle à la maison ',)]\n",
            "[('Calm down',), ('Calmezvous ',)]\n",
            "[('Calm down',), ('Du calme',)]\n",
            "[('Calm down',), ('Tranquille',)]\n",
            "[('Calm down',), ('Calmetoi',)]\n",
            "[('Calm down',), ('Du calme',)]\n",
            "[('Calm down',), ('Tranquille',)]\n",
            "[('Can we go',), ('Pouvonsnous partir ',)]\n",
            "[('Can we go',), ('Pouvonsnous nous en aller ',)]\n",
            "[('Can we go',), ('Pouvonsnous y aller ',)]\n",
            "[('Catch Tom',), ('Attrape Tom',)]\n",
            "[('Catch Tom',), ('Attrapez Tom',)]\n",
            "[('Catch him',), ('Attrapele\\u202f',)]\n",
            "[('Catch him',), ('Rattrapele',)]\n",
            "[('Catch him',), ('Saisissezle',)]\n",
            "[('Chill out',), ('Calmetoi',)]\n",
            "[('Chill out',), ('Tranquille',)]\n",
            "[('Choose me',), ('Choisismoi ',)]\n",
            "[('Come back',), ('Reviens ',)]\n",
            "[('Come back',), ('Revenez ',)]\n",
            "[('Come here',), ('Viens ici',)]\n",
            "[('Come here',), ('Venez là',)]\n",
            "[('Come over',), ('Venez ici ',)]\n",
            "[('Come over',), ('Viens chez nous ',)]\n",
            "[('Come over',), ('Venez chez nous ',)]\n",
            "[('Come over',), ('Viens chez moi ',)]\n",
            "[('Come over',), ('Venez chez moi ',)]\n",
            "[('Come soon',), ('Viens bientôt ',)]\n",
            "[('Come soon',), ('Venez bientôt ',)]\n",
            "[('Cool down',), ('Calmezvous ',)]\n",
            "[('Did I win',), ('Aije gagné ',)]\n",
            "[('Did I win',), ('Laije emporté ',)]\n",
            "[('Did I win',), ('Estce moi qui ai gagné ',)]\n",
            "[('Do it now',), ('Faitesle maintenant',)]\n",
            "[('Dogs bark',), ('Des chiens aboient',)]\n",
            "[('Dogs bark',), ('Les chiens aboient',)]\n",
            "[('Dont ask',), ('Ne demande pas ',)]\n",
            "[('Dont cry',), ('Ne pleure pas ',)]\n",
            "[('Dont die',), ('Ne meurs pas ',)]\n",
            "[('Dont die',), ('Ne mourez pas ',)]\n",
            "[('Dont lie',), ('Ne mens pas',)]\n",
            "[('Dont lie',), ('Ne mens pas ',)]\n",
            "[('Dont run',), ('Ne courez pas',)]\n",
            "[('Dont run',), ('Ne cours pas',)]\n",
            "[('Excuse me',), ('Excusemoi',)]\n",
            "[('Excuse me',), ('Excusezmoi',)]\n",
            "[('Excuse me',), ('Pardon\\u202f',)]\n",
            "[('Excuse me',), ('Je vous demande pardon\\u202f',)]\n",
            "[('Excuse me',), ('Plaîtil\\u202f',)]\n",
            "[('Excuse me',), ('Plaitil\\u202f',)]\n",
            "[('Excuse me',), ('Pardon ',)]\n",
            "[('Fantastic',), ('Fantastique\\u202f',)]\n",
            "[('Fantastic',), ('Fantastique\\xa0',)]\n",
            "[('Fantastic',), ('Sensass ',)]\n",
            "[('Feel this',), ('Sens ça ',)]\n",
            "[('Feel this',), ('Sentez ça ',)]\n",
            "[('Feel this',), ('Touche ça ',)]\n",
            "[('Feel this',), ('Touchez ça ',)]\n",
            "[('Film this',), ('Filmez ceci',)]\n",
            "[('Film this',), ('Filme ceci',)]\n",
            "[('Follow me',), ('Suismoi',)]\n",
            "[('Follow us',), ('Suisnous ',)]\n",
            "[('Follow us',), ('Suiveznous ',)]\n",
            "[('Forget it',), ('Oublie ',)]\n",
            "[('Forget it',), ('Oubliele ',)]\n",
            "[('Forget it',), ('Oubliez ',)]\n",
            "[('Forget it',), ('Oubliezle ',)]\n",
            "[('Forget it',), ('Laissez tomber',)]\n",
            "[('Forget it',), ('Oubliez ça ',)]\n",
            "[('Forget it',), ('Laisse tomber',)]\n",
            "[('Forget it',), ('Oublie',)]\n",
            "[('Forget it',), ('Oubliele ',)]\n",
            "[('Forget it',), ('Laissez tomber',)]\n",
            "[('Forget it',), ('Oubliez ça ',)]\n",
            "[('Forget me',), ('Oubliemoi',)]\n",
            "[('Forget me',), ('Oubliezmoi',)]\n",
            "[('Get a job',), ('Trouve un emploi ',)]\n",
            "[('Get a job',), ('Trouve un boulot ',)]\n",
            "[('Get a job',), ('Trouvez un emploi ',)]\n",
            "[('Get a job',), ('Trouvez un boulot ',)]\n",
            "[('Get a saw',), ('Va chercher une scie',)]\n",
            "[('Get going',), ('Vasy',)]\n",
            "[('Get going',), ('Allezy',)]\n",
            "[('Get going',), ('Marche',)]\n",
            "[('Get going',), ('Avance',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fr_sentence = (\"\",)\n",
        "eng_sentence = (\"hi\",)\n",
        "encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, fr_sentence)\n",
        "predictions = transformer(eng_sentence,\n",
        "                          fr_sentence,\n",
        "                          encoder_self_attention_mask.to(device),\n",
        "                          decoder_self_attention_mask.to(device),\n",
        "                          decoder_cross_attention_mask.to(device),\n",
        "                          enc_start_token=False,\n",
        "                          enc_end_token=False,\n",
        "                          dec_start_token=True,\n",
        "                          dec_end_token=False)\n",
        "next_token_prob_distribution = predictions[0] # not actual probs\n",
        "next_token_index = torch.argmax(next_token_prob_distribution,axis=1)\n",
        "for idx in next_token_index:\n",
        "      if idx == french_to_index[END_TOKEN]:\n",
        "        break\n",
        "      fr_sentence = (fr_sentence[0] + index_to_french[idx.item()], )\n",
        "print(f\"Evaluation translation (hi) : {fr_sentence}\")\n",
        "print(\"-------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZJPojv4lsxU",
        "outputId": "af19e2ca-f6fb-4d75-fb1b-c9244ce8062d"
      },
      "id": "kZJPojv4lsxU",
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('TompartirlaavonsBonjourviandeJepartirJeDétendezvous\\u202fIlpartiraJeJeaResteaIlDétendezvous\\u202favonslaàmangealentementaaaResteaDétendezvous\\u202fJeaDétendezvous\\u202fBonjourIlcœuraJemeagardesaJeIldûJeBonjourstableJepartirmeJeJemeallerBonjournouveau\\u202fJeJeavonsDétendezvous\\u202fJeJedûJeDétendezvous\\u202fBonjourdûneJeBonjourBonjourfautSoismeBonjourDétendezvous\\u202fpiquéSoisBonjourlentementmeJeJemeJeDétendezvous\\u202fDétendezvous\\u202fJeDétendezvous\\u202fmegardesmePrendsyDétendezvous\\u202fBonjourDétendezvous\\u202fapayéJeDétendezvous\\u202fJemeJeIlJeIlJemangeaaJeDétendezvous\\u202fmemesuismeDétendezvous\\u202fIlpayéapayéDétendezvous\\u202fpayéDétendezvous\\u202fmeResteJeDétendezvous\\u202fJememe',)\n",
            "-------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.train()\n",
        "transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    iterator = iter(train_loader)\n",
        "    for batch_num, batch in enumerate(iterator):\n",
        "        transformer.train()\n",
        "        eng_batch, fr_batch = batch\n",
        "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, fr_batch)\n",
        "        optim.zero_grad()\n",
        "        fr_predictions = transformer(eng_batch,\n",
        "                                     fr_batch,\n",
        "                                     encoder_self_attention_mask.to(device),\n",
        "                                     decoder_self_attention_mask.to(device),\n",
        "                                     decoder_cross_attention_mask.to(device),\n",
        "                                     enc_start_token=False,\n",
        "                                     enc_end_token=False,\n",
        "                                     dec_start_token=True,\n",
        "                                     dec_end_token=True)\n",
        "        labels = transformer.decoder.sentence_embedding.batch_tokenize(fr_batch, start_token=False, end_token=True)\n",
        "        loss = criterian(\n",
        "            fr_predictions.view(-1, fr_vocab_size).to(device),\n",
        "            labels.view(-1).to(device)\n",
        "        ).to(device)\n",
        "        valid_indicies = torch.where(labels.view(-1) == french_to_index[PADDING_TOKEN], False, True)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        #train_losses.append(loss.item())\n",
        "        if batch_num % len(batch) == 0:\n",
        "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
        "            print(f\"English: {eng_batch[0]}\")\n",
        "            print(f\"french Translation: {fr_batch[0]}\")\n",
        "            fr_sentence_predicted = torch.argmax(fr_predictions[0], axis=1)\n",
        "            predicted_sentence = \"\"\n",
        "            for idx in fr_sentence_predicted:\n",
        "              if idx == french_to_index[END_TOKEN]:\n",
        "                break\n",
        "              predicted_sentence += index_to_french[idx.item()]\n",
        "            print(f\"french Prediction: {predicted_sentence}\")\n",
        "\n",
        "            transformer.eval()\n",
        "            fr_sentence = (\"\",)\n",
        "            eng_sentence = (\"hi\",)\n",
        "            encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, fr_sentence)\n",
        "            predictions = transformer(eng_sentence,\n",
        "                                      fr_sentence,\n",
        "                                      encoder_self_attention_mask.to(device),\n",
        "                                      decoder_self_attention_mask.to(device),\n",
        "                                      decoder_cross_attention_mask.to(device),\n",
        "                                      enc_start_token=False,\n",
        "                                      enc_end_token=False,\n",
        "                                      dec_start_token=True,\n",
        "                                      dec_end_token=False)\n",
        "            next_token_prob_distribution = predictions[0] # not actual probs\n",
        "            next_token_index = torch.argmax(next_token_prob_distribution,axis=1)\n",
        "            for idx in next_token_index:\n",
        "                  if idx == french_to_index[END_TOKEN]:\n",
        "                    break\n",
        "                  fr_sentence = (fr_sentence[0] + index_to_french[idx.item()], )\n",
        "            print(f\"Evaluation translation (hi) : {fr_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V0bzbMwhSh56",
        "outputId": "f5014250-e364-4e44-da6a-f551ce7ff577"
      },
      "id": "V0bzbMwhSh56",
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 0 : 10.47547435760498\n",
            "English: Go\n",
            "french Translation: Va \n",
            "french Prediction: nousBonjourconcentréeaDétendezvous IlIlJeBonjourmariéEnSoislemeDétendezvous payésuisBonjourstableJepartirsuisyResteàIlavonsfautlefaisaisJeydûJenedûJeSoisJeàaamestableJesourisDétendezvous JeDétendezvous dûdûenadûaavonsJeJeaDétendezvous EllesResteàDétendezvous JeJeJeàResteDétendezvous JaimememeaDétendezvous medûNoussuisaIlBonjourDétendezvous JeDétendezvous Détendezvous ymeJeDétendezvous JeameyDétendezvous IlenmeJemeJeEnmeResteavezmefauteJeDétendezvous yJestablenemeDétendezvous meJeallermeàJeJedûBonjourResteJeJeoùpartirpayéDétendezvous Détendezvous IlpayéstableDétendezvous Détendezvous yyIla\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('VaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVa',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 2 : 10.440921783447266\n",
            "English: Go\n",
            "french Translation: En route \n",
            "french Prediction: VaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVa\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('VaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVa',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 4 : 10.63138484954834\n",
            "English: Hi\n",
            "french Translation: Salut \n",
            "french Prediction: VaVaVaVaVaVaVaVaVaMarcheVaVaVaVaVaVaVaMarcheVaVaVaVaMarcheVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaMarcheVaVaVaVaVaVaVaVaVaVaMarcheVaVaVaMarcheVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaMarcheVaVaVaVaVaVaMarcheVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaVaMarcheVaVaVaVaVaVaVaVaVaVaVaVaVa\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('MarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarche',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 6 : 10.516085624694824\n",
            "English: Run\n",
            "french Translation: Cours \n",
            "french Prediction: MarcheMarcheMarcheVaMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheBougeMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheBougeMarcheMarcheMarcheMarcheMarcheBougeMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheBougeMarcheMarcheBougeMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheBougeBougeMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheVaMarcheBougeMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheBougeMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheVaMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheBougeMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheBougeMarcheMarcheBougeMarcheVaMarcheMarcheMarcheMarcheMarcheMarcheBougeMarcheBougeMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarcheMarche\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('BougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBouge',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 8 : 10.386759757995605\n",
            "English: Run\n",
            "french Translation: Prenez vos jambes à vos cous \n",
            "french Prediction: BougeBougeBougeVaBougeBougeMarcheBougeMarcheMarcheBougeBougeBougeBougeBougeSalutMarcheBougeBougeBougeSalutMarcheBougeBougeBougeMarcheBougeBougeBougeBougeBougeMarcheBougeMarcheBougeBougeBougeMarcheBougeMarcheBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeMarcheMarcheBougeBougeBougeBougeBougeMarcheBougeBougeBougeMarcheBougeMarcheBougeBougeBougeBougeBougeBougeBougeMarcheBougeBougeBougeBougeVaBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeMarcheBougeBougeMarcheBougeMarcheBougeBougeBougeBougeMarcheBougeBougeBougeBougeBougeBougeBougeMarcheBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeMarcheMarcheBougeBougeBougeBougeBougeMarcheBougeBougeBougeMarcheBougeMarcheBougeBougeMarcheBougeBougeMarche\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutBougeBougeBougeBougeBougeBougeSalutBougeBougeBougeSalutSalutSalutSalutBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBougeBouge',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 10 : 10.431541442871094\n",
            "English: Run\n",
            "french Translation: Filez \n",
            "french Prediction: SalutSalutSalutSalutBougeSalutBougeSalutSalutSalutSalutSalutSalutBougeSalutBougeSalutSalutSalutBougeSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutBougeSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutBougeSalutSalutSalutSalutSalutSalutBougeBougeBougeBougeSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutBougeSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutBougeSalutSalutSalutSalutSalutBougeBougeSalutSalutSalutBougeSalutBougeSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutBougeSalutSalutSalutSalutSalutSalutSalutBougeSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutBougeSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutBougeBougeSalutBougeBougeBouge\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 12 : 10.092057228088379\n",
            "English: Run\n",
            "french Translation: Fuyez \n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 14 : 9.29073429107666\n",
            "English: Run\n",
            "french Translation: Cours \n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 16 : 9.864845275878906\n",
            "English: Run\n",
            "french Translation: Prenez vos jambes à vos cous \n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutCourez SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutCourez SalutSalutSalutSalutSalutCourez SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutCourez SalutSalutSalutCourez Courez SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutCourez SalutSalutSalutSalutCourez SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutCourez Courez SalutCourez SalutSalutSalutSalutCourez SalutSalutSalutSalutCourez SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('Courez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202f',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 18 : 9.531041145324707\n",
            "English: Run\n",
            "french Translation: Filez \n",
            "french Prediction: Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez SalutCourez Courez SalutCourez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez SalutCourez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez SalutCourez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez \n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('Courez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202f',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 20 : 9.250703811645508\n",
            "English: Run\n",
            "french Translation: Fuyez \n",
            "french Prediction: Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez \n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('Courez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202f',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 22 : 10.318634033203125\n",
            "English: Who\n",
            "french Translation: Qui \n",
            "french Prediction: Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Cours Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez \n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('Courez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202f',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 24 : 10.281540870666504\n",
            "English: Wow\n",
            "french Translation: Waouh \n",
            "french Prediction: Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez \n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('Courez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202f',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 26 : 10.600885391235352\n",
            "English: Duck\n",
            "french Translation: À terre \n",
            "french Prediction: CoursCourez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez \n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('Courez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202f',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 28 : 10.509965896606445\n",
            "English: Duck\n",
            "french Translation: Baissezvous \n",
            "french Prediction: Courez Courez CoursCoursCoursCoursCoursCourez CoursCourez Courez CoursCourez Courez Courez Courez CoursCourez Courez Courez CoursCourez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez CoursCourez Courez Courez CoursCourez Courez CoursCourez Courez Courez CoursCourez Courez Courez CoursCourez Courez CoursCoursCourez CoursCoursCourez CoursCoursCoursCourez CoursCoursCourez Courez Courez Courez Courez Courez Courez CoursCoursCourez Courez Courez Courez Courez CoursCourez CoursCourez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez Courez CoursCourez Courez CoursCoursCourez CoursCourez Courez Courez CoursCourez Courez CoursCoursCourez Courez CoursCourez Courez Courez Courez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez Courez Courez Courez CoursCourez Courez Courez Courez Courez Courez Courez Courez \n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('Courez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202f',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 30 : 10.32685375213623\n",
            "English: Help\n",
            "french Translation: À laide \n",
            "french Prediction: CoursCourez CoursCourez CoursCoursCoursCoursCoursCoursCoursCourez Courez CoursCoursCourez CoursCoursCoursCourez CoursCoursCoursCourez Courez CoursCourez CoursCoursCoursCoursCourez CoursCoursCoursCoursCourez CoursCoursCoursCourez CoursCoursCourez Courez Courez Courez CoursCourez Courez CoursCourez CoursCoursCoursCourez Courez CoursCourez CoursCoursCourez Courez Courez CoursCourez CoursCoursCourez Courez CoursCourez Courez CoursCoursCourez Courez Courez Courez CoursCourez CoursCoursCourez Courez CoursCourez Courez CoursCourez Courez CoursCourez Courez Courez CoursCourez Courez CoursCourez CoursCourez Courez CoursCourez CoursCourez Courez CoursCourez CoursCoursCoursCourez Courez Courez Courez CoursCourez CoursCourez Courez Courez Courez Courez CoursCoursCourez Courez Courez Courez Courez Courez Courez Courez CoursCourez Courez CoursCourez Courez CoursCourez CoursCoursCourez CoursCourez CoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('Courez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202fCourez\\u202f',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 32 : 10.386605262756348\n",
            "English: Hide\n",
            "french Translation: Cachezvous\n",
            "french Prediction: Courez CoursCourez Courez CoursCoursCourez Courez Courez Courez CoursCourez CoursCoursCoursCourez CoursCoursCoursCoursCoursCoursCourez Courez Courez FuyonsCourez Courez CoursCourez CoursCourez CoursFuyonsCoursCoursCourez CoursCourez Courez CoursCourez CoursCourez CoursCoursCoursCourez CoursCoursCourez Courez CoursCourez CoursCourez Courez Courez CoursCoursCourez Courez FuyezCourez Courez Courez Courez Courez CoursCourez CoursCourez Courez CoursCourez Courez CoursCourez Courez Courez CoursCoursCoursCourez Courez Courez CoursCoursCoursCoursCoursCoursCourez Courez FuyezCoursCourez Courez Courez CoursCourez CoursCourez Courez CoursCourez CoursCoursCourez CoursCoursCourez CoursCoursCourez Courez CoursCourez Courez CoursCoursCourez Courez Courez CoursCourez Courez Courez Courez CoursCoursCoursCoursCoursCourez Courez Courez CoursCoursCourez Courez Courez Courez CoursCourez CoursCourez Courez CoursCourez \n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 34 : 10.053131103515625\n",
            "English: Jump\n",
            "french Translation: Saute\n",
            "french Prediction: CoursCourez Courez CoursCourez CoursCoursCoursCourez CoursCourez CoursCoursCoursCourez CoursCoursCoursCoursCourez CoursCourez Courez Courez CoursCoursCoursCoursCoursCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCourez CoursCoursCoursCoursCoursCoursCourez Courez CoursCoursCourez CoursCourez CoursCourez CoursCoursCoursCoursCourez CoursCoursCoursCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCourez CoursCoursCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCourez Courez CoursCourez Courez Courez CoursCoursCourez Courez CoursCoursCoursCoursCoursCoursCoursCoursCoursCourez CoursCoursCourez CoursCourez CoursCoursFuyonsCoursCoursCoursCourez CoursCoursCoursCoursCoursCourez CoursCourez CoursCoursCoursCoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 36 : 10.183158874511719\n",
            "English: Stop\n",
            "french Translation: Stop \n",
            "french Prediction: CoursCoursCoursCoursCoursCoursCoursCoursCoursCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCourez Courez CoursCoursCoursCoursCoursCoursCourez Courez CoursCoursCoursCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCourez CoursCoursCoursFuyonsFuyezCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCourez Courez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyezCourez CoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 38 : 10.594595909118652\n",
            "English: Wait\n",
            "french Translation: Attends \n",
            "french Prediction: CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCourez CoursCoursCoursCoursCoursFuyonsFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCourez CoursCoursCoursCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 40 : 10.283792495727539\n",
            "English: Wait\n",
            "french Translation: Attendez\n",
            "french Prediction: CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCourez CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCourez CoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 42 : 9.850456237792969\n",
            "English: Wait\n",
            "french Translation: Attendez \n",
            "french Prediction: CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 44 : 9.371331214904785\n",
            "English: Wait\n",
            "french Translation: Attendez\n",
            "french Prediction: CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 46 : 10.327704429626465\n",
            "English: Begin\n",
            "french Translation: Commence\n",
            "french Prediction: CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 48 : 10.395147323608398\n",
            "English: Go on\n",
            "french Translation: Continuez\n",
            "french Prediction: CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursAttendezCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursFuyonsCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('CoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCoursCours',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 50 : 10.390317916870117\n",
            "English: Hello\n",
            "french Translation: Bonjour \n",
            "french Prediction: CoursCoursAttendezCoursCoursAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezAttendezCoursCoursAttendezAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezCoursAttendezAttendezCoursAttendezAttendezCoursAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezCoursCoursAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezCoursCoursCoursCoursAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezCoursCoursCoursAttendezCoursAttendezAttendezCoursAttendezCoursAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezAttendez\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('AttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendez',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 52 : 10.161916732788086\n",
            "English: Hello\n",
            "french Translation: Bonjour \n",
            "french Prediction: AttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendez\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('AttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendez',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 54 : 9.879927635192871\n",
            "English: Hello\n",
            "french Translation: Bonjour\n",
            "french Prediction: AttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendez\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('AttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendez',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 56 : 10.422922134399414\n",
            "English: I see\n",
            "french Translation: Je comprends\n",
            "french Prediction: AttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezCoursAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendez\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('AttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendezAttendez',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 58 : 10.427892684936523\n",
            "English: I try\n",
            "french Translation: Jessaye\n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutAttendezSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutAttendezSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutAttendezSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 60 : 10.358624458312988\n",
            "English: I won\n",
            "french Translation: Je lai emporté \n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 62 : 10.374957084655762\n",
            "English: Oh no\n",
            "french Translation: Oh non \n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 64 : 10.35412311553955\n",
            "English: Relax\n",
            "french Translation: Détendstoi \n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 66 : 10.379129409790039\n",
            "English: Relax\n",
            "french Translation: Relaxe Max \n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Iteration 68 : 10.332038879394531\n",
            "English: Relax\n",
            "french Translation: Du calme \n",
            "french Prediction: SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n",
            "Evaluation translation (hi) : ('SalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalutSalut',)\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DATA PREPROCESSING DONE\n",
            "ENCODER COMPLETED\n",
            "DECODER ACTIVATED\n",
            "---------tokenization done --------\n",
            "---------Sentence Embedding done --------\n",
            "---------Positional Encoding done --------\n",
            "DECODER completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-191-cf45f5ccfcbe>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvalid_indicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m#train_losses.append(loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 state_steps)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    312\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tkjmcb94UlTz"
      },
      "id": "tkjmcb94UlTz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}